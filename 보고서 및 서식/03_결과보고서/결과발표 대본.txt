1. 인사
안녕하세요 종프 4조 발표를 맡은 이건형입니다.
저희 조의 주제는 인공지능 기반 장애인주차표시 인식 시스템 개발입니다.

2. 목차 설명
발표 순서는 다음과 같습니다.

3. 과제 목적 및 필요성
요즘 장애인전용 주차장이 많이 생겼는데요. 그만큼 장애인주차구역에 불법으로 주차하는 차량도 많이 생겼습니다. 그러한 불법 주차를 막기 위해서 현재 직접적으로 인력을 투입하거나 사물인터넷을 사용해서 단속을 하고 있습니다. 하지만 인력의 부족과 비용적인 측면, 공간적인 측면에서 보다 경제적인 시스템이 필요하다고 생각하여 딥러닝 기반의 장애인주차구역 감시 시스템을 개발하여 직접적인 인력의 투입없이 불법 주차한 차량을 감지하고 이를 단속에 활용할 수 있는 S/W 개발을 목표로 하였습니다.

4. 프로젝트 개요
그럼 프로젝트의 전체적인 흐름을 설명드리겠습니다. 보시는 그림과 같이 먼저 CCTV에서 주차된 차량을 촬영합니다. 해당 사진을 판독 서버에 전송합니다. 그 다음 AI가 이 사진이 장애인차량이 맞는지 아닌지 판독을 합니다. 해당 사진이 장애인차량이 아니라면 불법주차가 발생했다는 사실을 경찰에게 알립니다. 그럼 여기서 저희가 해야할 일은 첫번째 AI 모델을 학습하는 것입니다. 두번째는 그 AI를 가지고 장애인 주차 표시를 판독하는 프로그램을 구현하는 것입니다.

5. AI 모델 학습 과정
그럼 이제 말씀드렸던 AI 모델을 학습시키는 과정을 설명드리겠습니다. 저희는 AI를 학습시키는 방법으로 딥러닝 모델 중 하나인 Yolo를 사용하였는데요. 먼저 Yolo가 작동하는 원리에 대해서 간단하게 설명 드리겠습니다.
<작동 원리 설명>
먼저 사진이 Input으로 들어옵니다. 사진들은 이진 데이터들의 행렬인데 여기에  weight와 bias라고 하는 가중치를 곱하고 더합니다. 이를 여러 번 반복하면 하나의 예측값이 나오는데요. 이를 실제 우리가 도출하고자 하는 값과 비교하여 가중치를 업데이트합니다. 그래서 이 과정을 여러 번 반복하여 최고의 예측값을 도출하는 그 가중치를 계산하는 것이 AI 학습 목표입니다.

이제 실제로 학습하는 세부적인 과정을 설명드리겠습니다. 먼저 무엇을 학습시킬 것인지 학습시키기 위한 자료가 필요하겠죠? 그래서 장애인주차장을 돌아다니며 총 731장의 사진을 찍었습니다.

 그리고 AI에게 우리가 탐지하고자 하는 이미지가 무엇인지 알려줘야 하기 때문에 그림과 같이 네모나게 박스를 쳐서 라벨링을 합니다. 

그 후에 사진들을 여러가지 버젼으로 만들어 학습시키기 위해 데이터 셋을 만듭니다. 인식률을 높이기 위해 사진들의 크기를 조정하고, 조금 회전값을 넣어주기도 하고, 살짝 기울여도 주고 하는 과정을 Data Augmentation혹은 Preprocessing, 데이터 전처리과정이라고 합니다. 

그래서 최종적으로 만들어진 데이터셋을 학습시킵니다. 아까 설명드린 Yolo 동작 원리에서 보신 것처럼 가중치를 계산하는 과정에서 여러가지 환경 변수들을 바꿀 수가 있습니다. 그 중에서 몇 번 학습을 할 것인지 횟수를 정하는 epoch와 가중치를 한 번 업데이트 할 때 사용되는 샘플들의 묶을을 나타내는 batch값을 바꿔가면서 언제 모델이 가장 효율적으로 훈련되는지를 실험했습니다. 그래서 시간 대비 가장 높은 인식률을 가지는 값은 batch가 16, epoch가 250일 때이었습니다. 

이 사진은 저희가 실험한 결과들을 공유하던 그림입니다. 

그런 다음, 라벨링에 따라서도 인식률이 어떻게 달라지는지에 대해서도 실험을 해보았습니다. 보시면 첫번째 Case가 장애인주차표시만을 라벨링한 데이터셋이고, 두번째 Case는 장애인주차표시와 아파트표지도 같이 라벨링해서 만든 데이터셋입니다. 그래서 각각의 Case별로 최고의 가중치를 계산하여 나온 Best.pt파일을 가지고 탐지를 해본 결과는 다음과 같습니다.

좌측은 Case 별 loss value와 mAP값을 나타내구요. 우측 그림은 테스트한 사진들의 예시인데 탐지한 객체를 얼마만큼 신뢰하는지에 대한 값을 보여줍니다. 가장 위쪽 그림은 장애인주차표시만 붙어있는 차량이구요. 그 밑에 그림은 장애인주차표시가 없고 아파트표지만 붙어있는 차량입니다. 그리고 마지막 그림은 둘 다 붙어있는 차량으로 테스트를 해보았습니다. 보시면 두번째 Case 즉, 장애인주차표시와 아파트표지를 같이 라벨링했을 때 더 좋은 결과를 내는 것을 볼 수 있습니다.

그래서 이렇게 직접 실험한 과정과 결과들을 논문으로 작성하여 한국멀티미디어학회에서 주최한 2021년도 추계학술발표대회에 공동 제 1저자로 제출하였습니다. 대회는 11월 26일에 진행되었고 코로나로 인해 비대면 발표로 진행하였습니다. 아래의 링크를 통해서 대회 발표영상을 볼 수 있습니다.

6. 탐지 프로그램 구현
이제 학습한 AI로 불법 주차를 잡아내는 판독 프로그램을 만들었습니다. 앞서 말씀드린 저희 프로젝트 흐름을 보시면 CCTV로 촬영을 하고 서버로 전송하는데 기업에서 제공하는 CCTV가 없어 대신하여 안드로이드 어플로 구현했습니다. DB와 서버도 따로 제공받지 않아 저희가 자체적으로 Firebase Realtime Database와 Storage로 DB를 구성했고, 서버도 로컬환경으로 작성하였습니다. 그 후 판독한 결과를 경찰 서버에 전송하는 과정은 SMS API를 이용하여 휴대폰으로 전송하도록 했습니다.

CCTV 역할을 하는 어플은 다음과 같이 UI를 구성했습니다. 사진을 촬영해서 전송 버튼을 누르면 해당 DB로 위치 정보와 시간정보를 담아 사진을 전송합니다. DB에 담긴 모습은 다음 그림과 같습니다.

DB에 데이터가 수신되면 서버에서 이를 감지하여 장애인차량이 맞는지 판독을 하는데요. 판독하는 주요 코드를 살펴보겠습니다. 이 부분은 프로그램에 사용되는 상수를 설정하는 부분입니다. 이제 db에서 이미지를 불러와 detect함수를 실행하면 모델에 저희가 도출한 Best.pt를 넣어준 뒤, stride를 설정해줍니다. 예를 들어, Stirde값이 32라면 416X416 image를 32로 나누어 13X13의 box들로 나뉘어집니다. 16이라면 26X26, 8이라면 52X52로 나뉘어집니다.

이렇게 나뉜 박스들을 먼저 특정한 threshold 값 이하의 점수를 가진 box들을 무시하면서 걸러줍니다. 우측 예시 사진을 보면 한번 걸러서 차량 주변에만 bounding box들이 남아있는걸 볼수 있습니다. 그 후 Non-maximum Suprression을 해주는데 이는 동일한 이미지를 여러번  detect하는 것을 방지해줍니다. 그래서 하나의 bounding box만이 남은 것을 볼 수 있습니다.

이제 걸러진 bounding box를 이미지에 클래스 이름과 confidence 값을 함께 붙여줍니다.

그렇게 붙여진 라벨을 읽으면서 장애인주차표시가 맞는지 확인을 하고 confidence 값이 0.5이하이면 사진과 함께 위치정보를 mms로 문자를 날립니다. 여기까지가 저희가 구현한 프로그램이구요. 이를 실시간으로 동작하는 모습을 데모 영상으로 담았습니다. 함께 보시겠습니다.